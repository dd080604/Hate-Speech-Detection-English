{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded shapes:\n",
      "(12000, 13870) (12000,)\n",
      "(3000, 13870) (3000,)\n",
      "(10001, 13870)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.00027558257290665735), np.float64(0.026846531679251332))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np, pickle\n",
    "\n",
    "ROOT = Path.cwd().parent\n",
    "sys.path.append(str(ROOT))\n",
    "ART = ROOT / \"artifacts/word12\"\n",
    "\n",
    "with open(ART / \"feature_extractor.pickle\", \"rb\") as f:\n",
    "    fe = pickle.load(f)\n",
    "\n",
    "X_train = np.load(ART / \"X_train.npy\")\n",
    "y_train = np.load(ART / \"y_train.npy\")\n",
    "X_val = np.load(ART / \"X_val.npy\")\n",
    "y_val = np.load(ART / \"y_val.npy\")\n",
    "X_test = np.load(ART / \"X_test.npy\")\n",
    "\n",
    "print(\"Loaded shapes:\")\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "X_train.mean(), X_train.std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def train_linear_svm_sgd(\n",
    "    X, y,\n",
    "    lr=0.1,\n",
    "    reg=1e-4,          # L2 regularization strength (lambda)\n",
    "    epochs=10,\n",
    "    batch_size=512,\n",
    "    seed=42\n",
    "):\n",
    "    \"\"\"\n",
    "    Linear SVM with hinge loss using SGD.\n",
    "    y must be in {0,1}. Internally we use {-1,+1}.\n",
    "    Objective: (reg/2)||w||^2 + mean(max(0, 1 - y*(Xw+b)))\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # Convert labels to {-1, +1}\n",
    "    y_pm = np.where(y == 1, 1.0, -1.0)\n",
    "\n",
    "    n, d = X.shape\n",
    "    w = np.zeros(d, dtype=float)\n",
    "    b = 0.0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        idx = rng.permutation(n)\n",
    "\n",
    "        for start in range(0, n, batch_size):\n",
    "            batch_idx = idx[start:start + batch_size]\n",
    "            Xb = X[batch_idx]\n",
    "            yb = y_pm[batch_idx]\n",
    "\n",
    "            scores = Xb @ w + b\n",
    "            margins = yb * scores\n",
    "\n",
    "            # Hinge-active points: margins < 1\n",
    "            active = margins < 1.0\n",
    "            if np.any(active):\n",
    "                Xa = Xb[active]\n",
    "                ya = yb[active]\n",
    "\n",
    "                # Gradients (mean over batch active points)\n",
    "                grad_w_hinge = -(ya[:, None] * Xa).mean(axis=0)\n",
    "                grad_b_hinge = -(ya).mean()\n",
    "            else:\n",
    "                grad_w_hinge = 0.0\n",
    "                grad_b_hinge = 0.0\n",
    "\n",
    "            # Add L2 regularization gradient\n",
    "            grad_w = grad_w_hinge + reg * w\n",
    "            grad_b = grad_b_hinge  # usually we don't regularize bias\n",
    "\n",
    "            # SGD step\n",
    "            w -= lr * grad_w\n",
    "            b -= lr * grad_b\n",
    "\n",
    "        # Optional: quick progress print\n",
    "        # Compute average hinge loss on a small sample\n",
    "        # print(f\"epoch {epoch+1}/{epochs} done\")\n",
    "\n",
    "    return w, b\n",
    "\n",
    "def svm_scores(X, w, b):\n",
    "    return X @ w + b\n",
    "\n",
    "def predict_linear_svm(X, w, b):\n",
    "    # Classify by sign\n",
    "    scores = X @ w + b\n",
    "    return (scores >= 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score_binary(y_true, y_pred):\n",
    "    y_true = y_true.astype(int)\n",
    "    y_pred = y_pred.astype(int)\n",
    "\n",
    "    tp = int(((y_true == 1) & (y_pred == 1)).sum())\n",
    "    fp = int(((y_true == 0) & (y_pred == 1)).sum())\n",
    "    fn = int(((y_true == 1) & (y_pred == 0)).sum())\n",
    "\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    recall    = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "\n",
    "    f1 = (2 * precision * recall / (precision + recall)) if (precision + recall) > 0 else 0.0\n",
    "    return f1, precision, recall, tp, fp, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_threshold(scores, y_true, n_grid=200, print_every=25):\n",
    "    \"\"\"\n",
    "    Tune threshold t for y_pred = (scores >= t).\n",
    "    Uses a grid between score percentiles for stability.\n",
    "    \"\"\"\n",
    "    y_true = y_true.astype(int)\n",
    "\n",
    "    lo = np.percentile(scores, 1)\n",
    "    hi = np.percentile(scores, 99)\n",
    "    thresholds = np.linspace(lo, hi, n_grid)\n",
    "\n",
    "    best = {\"f1\": -1, \"t\": None, \"prec\": None, \"rec\": None, \"tp\": None, \"fp\": None, \"fn\": None}\n",
    "\n",
    "    for i, t in enumerate(thresholds, start=1):\n",
    "        y_pred = (scores >= t).astype(int)\n",
    "        f1, prec, rec, tp, fp, fn = f1_score_binary(y_true, y_pred)\n",
    "\n",
    "        if f1 > best[\"f1\"]:\n",
    "            best.update({\"f1\": f1, \"t\": float(t), \"prec\": prec, \"rec\": rec, \"tp\": tp, \"fp\": fp, \"fn\": fn})\n",
    "\n",
    "        if (i % print_every == 0) or (i == 1) or (i == len(thresholds)):\n",
    "            print(\n",
    "                f\"[{i:>3}/{len(thresholds)}] t={t:+.4f} | \"\n",
    "                f\"F1={f1:.4f} (P={prec:.3f}, R={rec:.3f}) | \"\n",
    "                f\"best F1={best['f1']:.4f} @ t={best['t']:+.4f}\"\n",
    "            )\n",
    "\n",
    "    print(\"\\nBEST:\")\n",
    "    print(\n",
    "        f\"t={best['t']:+.4f} | F1={best['f1']:.4f} | \"\n",
    "        f\"P={best['prec']:.4f} | R={best['rec']:.4f} | \"\n",
    "        f\"TP={best['tp']} FP={best['fp']} FN={best['fn']}\"\n",
    "    )\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1: 0.6224 | Precision: 0.7225 | Recall: 0.5467\n",
      "TP=492 FP=189 FN=408\n"
     ]
    }
   ],
   "source": [
    "w, b = train_linear_svm_sgd(\n",
    "    X_train, y_train,\n",
    "    lr=0.5,\n",
    "    reg=1e-3,\n",
    "    epochs=10,\n",
    "    batch_size=512,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "yhat_val = predict_linear_svm(X_val, w, b)\n",
    "f1, prec, rec, tp, fp, fn = f1_score_binary(y_val, yhat_val)\n",
    "\n",
    "print(f\"Validation F1: {f1:.4f} | Precision: {prec:.4f} | Recall: {rec:.4f}\")\n",
    "print(f\"TP={tp} FP={fp} FN={fn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1/300] t=-2.7593 | F1=0.4651 (P=0.303, R=1.000) | best F1=0.4651 @ t=-2.7593\n",
      "[ 30/300] t=-2.1548 | F1=0.4774 (P=0.314, R=0.998) | best F1=0.4774 @ t=-2.1548\n",
      "[ 60/300] t=-1.5295 | F1=0.5386 (P=0.371, R=0.984) | best F1=0.5386 @ t=-1.5295\n",
      "[ 90/300] t=-0.9042 | F1=0.7248 (P=0.605, R=0.904) | best F1=0.7248 @ t=-0.9042\n",
      "[120/300] t=-0.2789 | F1=0.6763 (P=0.702, R=0.652) | best F1=0.7409 @ t=-0.8208\n",
      "[150/300] t=+0.3464 | F1=0.5892 (P=0.780, R=0.473) | best F1=0.7409 @ t=-0.8208\n",
      "[180/300] t=+0.9718 | F1=0.4505 (P=0.875, R=0.303) | best F1=0.7409 @ t=-0.8208\n",
      "[210/300] t=+1.5971 | F1=0.2732 (P=0.864, R=0.162) | best F1=0.7409 @ t=-0.8208\n",
      "[240/300] t=+2.2224 | F1=0.1714 (P=0.924, R=0.094) | best F1=0.7409 @ t=-0.8208\n",
      "[270/300] t=+2.8477 | F1=0.0949 (P=0.938, R=0.050) | best F1=0.7409 @ t=-0.8208\n",
      "[300/300] t=+3.4731 | F1=0.0624 (P=0.967, R=0.032) | best F1=0.7409 @ t=-0.8208\n",
      "\n",
      "BEST:\n",
      "t=-0.8208 | F1=0.7409 | P=0.6397 | R=0.8800 | TP=792 FP=446 FN=108\n"
     ]
    }
   ],
   "source": [
    "scores_val = svm_scores(X_val, w, b)\n",
    "best = tune_threshold(scores_val, y_val, n_grid=300, print_every=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr=0.1 reg=1e-05 -> F1=0.5684 (P=0.697, R=0.480)\n",
      "lr=0.5 reg=1e-05 -> F1=0.5912 (P=0.738, R=0.493)\n",
      "lr=0.1 reg=0.0001 -> F1=0.5688 (P=0.698, R=0.480)\n",
      "lr=0.5 reg=0.0001 -> F1=0.5879 (P=0.742, R=0.487)\n",
      "lr=0.1 reg=0.001 -> F1=0.5684 (P=0.697, R=0.480)\n",
      "lr=0.5 reg=0.001 -> F1=0.5923 (P=0.736, R=0.496)\n",
      "lr=0.1 reg=0.01 -> F1=0.5722 (P=0.699, R=0.484)\n",
      "lr=0.5 reg=0.01 -> F1=0.5836 (P=0.724, R=0.489)\n",
      "Best: (0.5922974767596282, 0.5, 0.001)\n"
     ]
    }
   ],
   "source": [
    "regs = [1e-5, 1e-4, 1e-3, 1e-2]\n",
    "lrs  = [0.1, 0.5]\n",
    "\n",
    "best = (-1, None, None)\n",
    "\n",
    "for reg in regs:\n",
    "    for lr in lrs:\n",
    "        w, b = train_linear_svm_sgd(X_train, y_train, lr=lr, reg=reg, epochs=8, batch_size=512, seed=42)\n",
    "        yhat = predict_linear_svm(X_val, w, b)\n",
    "        f1, prec, rec, *_ = f1_score_binary(y_val, yhat)\n",
    "        print(f\"lr={lr} reg={reg} -> F1={f1:.4f} (P={prec:.3f}, R={rec:.3f})\")\n",
    "\n",
    "        if f1 > best[0]:\n",
    "            best = (f1, lr, reg)\n",
    "\n",
    "print(\"Best:\", best)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13.3 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "10e317046a0e9fb8162c0588e9823060f78a6881b28c35dfad39d75012d89739"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
